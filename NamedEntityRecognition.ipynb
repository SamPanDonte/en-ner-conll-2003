{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj6Eu-OqLgmF"
      },
      "source": [
        "# Named entity recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi8YTzccNFtH"
      },
      "source": [
        "## Utilities for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my4F3kaxNQQG"
      },
      "source": [
        "### Get device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "row-eA6uNSey"
      },
      "outputs": [],
      "source": [
        "from torch.cuda import is_available as is_cuda_available\n",
        "from torch.backends.mps import is_available as is_mps_available\n",
        "\n",
        "def get_device() -> str:\n",
        "    '''Returns device string with priority: cuda, mps and cpu'''\n",
        "    if is_cuda_available():\n",
        "        return 'cuda'\n",
        "    if is_mps_available():\n",
        "        return 'mps'\n",
        "    return 'cpu'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkOwovYJjuu4"
      },
      "source": [
        "### Training and evaluating utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6si4QvIvj54t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from time import time\n",
        "from torch.nn import Module\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "def _train_epoch(device: str, model: Module, data: IterableDataset, loss_fn: Module, optimizer: Optimizer):\n",
        "    '''Trains model for one epoch'''\n",
        "    batch_amount = len(data)\n",
        "    begin_time = time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    correct = 0\n",
        "    total_amount = 0\n",
        "\n",
        "    for index, (x, y) in enumerate(data, 1):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        out = model(x)\n",
        "\n",
        "        total_amount += torch.count_nonzero(out).item()\n",
        "        for i, j in zip(torch.argmax(out, dim=1), y):\n",
        "            if i == j and i != 0:\n",
        "                correct += 1\n",
        "\n",
        "        loss = loss_fn(out, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        elapsed = time() - begin_time\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        avarage_time = elapsed / index\n",
        "        average_loss = total_loss / index\n",
        "\n",
        "        remaining = avarage_time * (batch_amount - index)\n",
        "\n",
        "        print(f'Train: {index}/{batch_amount} | Eta: {remaining:>0.0f}s', end=' ')\n",
        "        print(f'| loss: {average_loss:>0.4f} - acc: {(correct / total_amount):>0.4f}', end='\\r')\n",
        "\n",
        "        if index == batch_amount:\n",
        "            print()\n",
        "\n",
        "\n",
        "def evaluate_model(device: str, model: Module, data: IterableDataset, loss_fn: Module):\n",
        "    '''Evaluates model with data'''\n",
        "    batch_amount = len(data)\n",
        "    begin_time = time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total_amount = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, (x, y) in enumerate(data, 1):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            out = model(x)\n",
        "\n",
        "            total_amount += torch.count_nonzero(out).item()\n",
        "            for i, j in zip(torch.argmax(out, dim=1), y):\n",
        "                if i == j and i != 0:\n",
        "                    correct += 1\n",
        "\n",
        "            elapsed = time() - begin_time\n",
        "            total_loss += loss_fn(out, y).item()\n",
        "\n",
        "            avarage_time = elapsed / index\n",
        "            average_loss = total_loss / index\n",
        "\n",
        "            remaining = avarage_time * (batch_amount - index)\n",
        "\n",
        "            print(f'Valid {index}/{batch_amount} | Eta: {remaining:>0.0f}s', end=' ')\n",
        "            print(f'| loss: {average_loss:>0.4f} - acc: {(correct / total_amount):>0.4f}', end='\\r')\n",
        "\n",
        "\n",
        "\n",
        "    loss = total_loss / batch_amount\n",
        "    print(f'Valid {batch_amount}/{batch_amount} | Eta: {0}s', end=' ')\n",
        "    print(f'| loss: {loss:>0.4f} - acc: {(correct / total_amount):>0.4f}')\n",
        "\n",
        "\n",
        "def train(device: str, model: Module, data: IterableDataset, valid: IterableDataset, loss_fn: Module, optimizer: Optimizer, epochs: int):\n",
        "    '''Trains model'''\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch + 1}/{epochs}')\n",
        "        _train_epoch(device, model, data, loss_fn, optimizer)\n",
        "        evaluate_model(device, model, valid, loss_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tycrm4UuM5Kw"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vh9HA_JM0tG"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q-S0-4Ee-Dfo"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/Colab Notebooks/NamedEntityRecognition'\n",
        "TRAIN_DIR = 'train'\n",
        "VALID_DIR = 'dev-0'\n",
        "TEST_DIR = 'test-A'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH1AbKD-QQg2"
      },
      "source": [
        "### Create vocabulary utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1xgU9zTRQULd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab, Vocab\n",
        "\n",
        "TAGS = {\n",
        "    'O': 0, 'B-ORG': 1, 'I-ORG': 2, 'B-PER': 3, 'I-PER': 4, 'B-LOC': 5,\n",
        "    'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8\n",
        "}\n",
        "\n",
        "TAGS_REV = {\n",
        "    0: 'O', 1: 'B-ORG', 2: 'I-ORG', 3: 'B-PER', 4: 'I-PER', 5: 'B-LOC',\n",
        "    6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'\n",
        "}\n",
        "\n",
        "def create_vocabulary(data) -> Vocab:\n",
        "    '''Creates vocabulary from dataset'''\n",
        "    counter = Counter()\n",
        "    for text in data:\n",
        "        counter.update(text.split())\n",
        "\n",
        "    vocabulary = vocab(counter, 1, ['<unk>'])\n",
        "    vocabulary.set_default_index(0)\n",
        "\n",
        "    return vocabulary\n",
        "\n",
        "\n",
        "def encode(vocab: Vocab, text: str) -> Tensor:\n",
        "    '''Encode word using vocabulary'''\n",
        "    return torch.tensor([vocab[token] for token in text.split()], dtype=torch.long)\n",
        "\n",
        "\n",
        "def encode_tag(text: str) -> Tensor:\n",
        "    '''Encode tag'''\n",
        "    return torch.tensor([TAGS[token] for token in text.split()], dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KufcCQ9GMXUH"
      },
      "source": [
        "### Load and basic prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OAn6IMusLfuU"
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "\n",
        "\n",
        "def load_data(dir: str, vocab: Vocab) -> tuple[list[Tensor], list[Tensor]]:\n",
        "    '''Loads data from folder'''\n",
        "    labels = []\n",
        "    data = []\n",
        "    with open(path.join(dir, 'in.tsv'), encoding='utf8') as data_file:\n",
        "        for line in data_file:\n",
        "            line = line.split('\\t')\n",
        "            if len(line) == 2:\n",
        "                labels.append(encode_tag(line[0].strip()))\n",
        "                data.append(encode(vocab, line[1]))\n",
        "            else:\n",
        "                data.append(encode(vocab, line[0]))\n",
        "    if path.exists(path.join(dir, 'expected.tsv')):\n",
        "        with open(path.join(dir, 'expected.tsv'), encoding='utf8') as label_file:\n",
        "            labels = [encode_tag(line.strip()) for line in label_file]\n",
        "    return data, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3L2xKl8lz9"
      },
      "source": [
        "### Custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q4BKXfiy8lz9"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Iterator\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "\n",
        "class VariableLengthDataset(IterableDataset):\n",
        "    '''Dataset that works with variable length inputs'''\n",
        "    def __init__(self, data: list[Tensor], labels: Tensor) -> None:\n",
        "        self.data = list(filter(lambda x: x[0].size() != torch.Size([0]), zip(data, labels)))\n",
        "\n",
        "    def __getitem__(self, index) -> tuple[Tensor, Any]:\n",
        "        return self.data[index]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __iter__(self) -> Iterator[tuple[Tensor, Any]]:\n",
        "        for item in self.data:\n",
        "          yield item\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2OATuCjVtNT"
      },
      "source": [
        "### Loading and encoding data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dRI-Taup8lz9"
      },
      "outputs": [],
      "source": [
        "vocabulary = create_vocabulary(map(lambda x: x.split('\\t')[1], open(path.join(BASE_PATH, TRAIN_DIR, 'in.tsv'), encoding='utf8')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1lT6eNeoVv3p"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels = load_data(path.join(BASE_PATH, TRAIN_DIR), vocabulary)\n",
        "valid_data, valid_labels = load_data(path.join(BASE_PATH, VALID_DIR), vocabulary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ezv_lR4J8lz9"
      },
      "outputs": [],
      "source": [
        "train_data = VariableLengthDataset(train_data, train_labels)\n",
        "valid_data = VariableLengthDataset(valid_data, valid_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHx9pchRY-3b"
      },
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4aIntHbboJG",
        "outputId": "b693624f-60a7-4350-9d81-e25bd52461ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "DEVICE = get_device()\n",
        "print(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IK5SZ14vZTjr"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 128\n",
        "LSTM_DIM = 128\n",
        "LSTM_LAYERS = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8d9pC1bZH0a",
        "outputId": "bf84bff8-d2b9-4216-ed19-7ee9b4bdfe9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (embedding): Embedding(23625, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=256, out_features=9, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import Linear, Module, ReLU, Embedding, LSTM, Dropout\n",
        "import torch.nn.functional as functional\n",
        "\n",
        "\n",
        "class NeuralNetwork(Module):\n",
        "    def __init__(self, vocab: Vocab):\n",
        "        super().__init__()\n",
        "        self.embedding = Embedding(len(vocab), EMBEDDING_DIM, padding_idx=0)\n",
        "        self.lstm = LSTM(EMBEDDING_DIM, LSTM_DIM, num_layers=LSTM_LAYERS, batch_first=True, bidirectional=True)\n",
        "        self.linear = Linear(LSTM_DIM * 2, len(TAGS))\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.embedding(input)\n",
        "        x, _ = self.lstm(x.view(len(input), 1, -1))\n",
        "        x = self.linear(x.view(len(input), -1))\n",
        "        logits = functional.log_softmax(x, dim=1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = NeuralNetwork(vocabulary).to(DEVICE)\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjdvNr-ib0HP"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xCdHvuavb2II",
        "outputId": "0a343d49-321a-4e3c-cfc7-09d1cf31000c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.5917 - acc: 0.0020\n",
            "Valid 215/215 | Eta: 0s | loss: 0.4569 - acc: 0.0045\n",
            "Epoch 2/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.3459 - acc: 0.0070\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3421 - acc: 0.0076\n",
            "Epoch 3/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.2284 - acc: 0.0101\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2956 - acc: 0.0090\n",
            "Epoch 4/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.1634 - acc: 0.0119\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2755 - acc: 0.0097\n",
            "Epoch 5/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.1278 - acc: 0.0130\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2661 - acc: 0.0102\n",
            "Epoch 6/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.1087 - acc: 0.0136\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2610 - acc: 0.0104\n",
            "Epoch 7/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0978 - acc: 0.0139\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2580 - acc: 0.0105\n",
            "Epoch 8/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0910 - acc: 0.0142\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2550 - acc: 0.0106\n",
            "Epoch 9/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0863 - acc: 0.0143\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2567 - acc: 0.0106\n",
            "Epoch 10/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0829 - acc: 0.0144\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2561 - acc: 0.0107\n",
            "Epoch 11/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0801 - acc: 0.0145\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2584 - acc: 0.0108\n",
            "Epoch 12/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0782 - acc: 0.0145\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2608 - acc: 0.0108\n",
            "Epoch 13/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0764 - acc: 0.0145\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2657 - acc: 0.0108\n",
            "Epoch 14/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0751 - acc: 0.0146\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2773 - acc: 0.0118\n",
            "Epoch 15/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0738 - acc: 0.0146\n",
            "Valid 215/215 | Eta: 0s | loss: 0.2882 - acc: 0.0118\n",
            "Epoch 16/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0729 - acc: 0.0147\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3108 - acc: 0.0118\n",
            "Epoch 17/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0721 - acc: 0.0147\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3179 - acc: 0.0118\n",
            "Epoch 18/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0715 - acc: 0.0147\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3442 - acc: 0.0118\n",
            "Epoch 19/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0709 - acc: 0.0148\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3423 - acc: 0.0118\n",
            "Epoch 20/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0704 - acc: 0.0148\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3334 - acc: 0.0121\n",
            "Epoch 21/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0699 - acc: 0.0148\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3453 - acc: 0.0121\n",
            "Epoch 22/50\n",
            "Train: 945/945 | Eta: 0s | loss: 0.0695 - acc: 0.0148\n",
            "Valid 215/215 | Eta: 0s | loss: 0.3525 - acc: 0.0121\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-993e178a23de>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-417230c0e556>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device, model, data, valid, loss_fn, optimizer, epochs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}/{epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-417230c0e556>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(device, model, data, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtotal_amount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.nn import NLLLoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "loss_fn = NLLLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "train(DEVICE, model, train_data, valid_data, loss_fn, optimizer, 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFGoJTU98lz-"
      },
      "outputs": [],
      "source": [
        "evaluate_model(DEVICE, model, valid_data, loss_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlwYF4W38lz-"
      },
      "source": [
        "## Saving the valid output data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_g9HVhjGhZlI"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_and_save(device: str, model: Module, data: list[Tensor], dir: str):\n",
        "    '''Evaluates model with data and saves results in out.tsv file'''\n",
        "    batch_amount = len(data)\n",
        "    begin_time = time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with open(path.join(dir, 'out.tsv'), 'w') as out_file:\n",
        "        with torch.no_grad():\n",
        "            for index, x in enumerate(data, 1):\n",
        "                x = x.to(device)\n",
        "\n",
        "                out = functional.softmax(model(x), dim=1)\n",
        "                label = torch.argmax(out, dim=1)\n",
        "\n",
        "                for j, i in enumerate(label):\n",
        "                    if j != 0:\n",
        "                        print(end=' ', file=out_file)\n",
        "                    print('{}'.format(TAGS_REV[i.item()]), file=out_file, end='')\n",
        "                print(file=out_file)\n",
        "\n",
        "                elapsed = time() - begin_time\n",
        "\n",
        "                avarage_time = elapsed / index\n",
        "\n",
        "                remaining = avarage_time * (batch_amount - index)\n",
        "\n",
        "                print(f'Progress {index}/{batch_amount} | Eta: {remaining:>0.0f}s', end='\\r')\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW38XJO18lz_",
        "outputId": "9bf4a542-2fea-475a-82f2-79099f09f4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress 215/215 | Eta: 0s\n"
          ]
        }
      ],
      "source": [
        "evaluate_model_and_save(DEVICE, model, [x for (x, _) in valid_data], path.join(BASE_PATH, VALID_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_z2I2Xzi8lz_"
      },
      "outputs": [],
      "source": [
        "test_data, _ = load_data(path.join(BASE_PATH, TEST_DIR), vocabulary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7iIugdM8lz_",
        "outputId": "7207b82e-81f3-43dc-ce56-879db2f8d76e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress 230/230 | Eta: 0s\n"
          ]
        }
      ],
      "source": [
        "evaluate_model_and_save(DEVICE, model, [x for x in test_data], path.join(BASE_PATH, TEST_DIR))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
